<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>Kunal Handa</title>
    <link rel="stylesheet" href="tufte.css"/>
    <link rel="stylesheet" href="latex.css"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>

  <body>
    <article>
      <h1 id="Kunal Handa">Kunal Handa</h1>
      <section>
        <p><label for="mn-figure-1" class="margin-toggle">&#8853;</label><input type="checkbox" id="mn-figure-1" class="margin-toggle"/><span class="marginnote"> <img src="img/me.jpg" onmouseover="this.src='img/yodie.jpg'" onmouseout="this.src='img/me.jpg'" border="0" width="400" height=auto></span></p>

        <p><span class="newthought">I am an MSc by Research student</span> at the University of Oxford advised by <a href="https://www.cs.ox.ac.uk/people/yarin.gal/website">Yarin Gal</a>. 

        <p>I am interested in language-grounded interactive learning: 1) building ML models that can continuously learn in the real world through interactions and collaborations with humans, and 2) understanding the broader societal implications of these interactions.  Concretely, I have explored how to improve <a href="https://arxiv.org/abs/2403.05534">language models' preference learning abilities</a> through user interaction, the failure modes of <a href="https://arxiv.org/abs/2212.10711">models in ambiguous scenarios</a> and how to prevent them, how models' can help facilitate <a href="https://arxiv.org/abs/2310.10637">better student-teacher interactions</a>, and how <a href="https://langcog.github.io/peekbank-website/docs/about-us/">children undertake this process</a> when first learning language.</p>

        <p>Previously, I was a linguistics and computer science undergrad at Brown University advised by <a href="https://cs.brown.edu/people/epavlick/">Ellie Pavlick</a> and <a href="https://chensun.me/index.html">Chen Sun</a>. I also spent two years at the <a href="https://nlp.stanford.edu/">Stanford NLP Group</a> and <a href="https://cocolab.stanford.edu/">Stanford CocoLab</a> advised by <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>, <a href="https://www.dorademszky.com/">Dora Demszky</a>, and <a href="https://cocolab.stanford.edu/ndg">Noah Goodman</a> with whom I continue to collaborate frequently.</p>

        <p>You can contact me at: kunal <var>[underscore]</var> handa <var>[at]</var> alumni <var>[dot]</var> brown <var>[dot]</var> edu</p>
      </section>

      <section>
        <h2 id="Publications">Publications</h2>
        <h3 id="Conference Papers">Preprints</h3>
        <p><cite><a href="https://arxiv.org/abs/2403.05534">Bayesian Preference Elicitation with Language Models</a></cite>
        <br><b>Kunal Handa</b>, Yarin Gal, Ellie Pavlick, Noah Goodman, Jacob Andreas, Alex Tamkin*, Belinda Z Li*.<label for="co-firstlast" class="margin-toggle sidenote-number"></label><input type="checkbox" id="co-firstlast" class="margin-toggle"/><span class="sidenote">* denotes equal contribution.</span> Under review, 2024.</p>
  
        <h3 id="Conference Papers">Conference Papers</h3>
        <p><cite><a href="https://arxiv.org/abs/2310.10637">“Mistakes Help Us Grow”: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms</a></cite>
        <br><b>Kunal Handa</b>, Margarett Clapper, Jessica Boyle, Rose E Wang, Diyi Yang, David S Yeager, Dorottya Demszky. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023.</p>

        <p><cite><a href="https://arxiv.org/abs/2311.02171">Emergence of Abstract State Representations in Embodied Sequence Modeling</a></cite>
        <br>Tian Yun*, Zilai Zeng*, <b>Kunal Handa</b>, Ashish V Thapliyal, Bo Pang, Ellie Pavlick, Chen Sun. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023.</p>

        <p><cite><a href="https://arxiv.org/abs/2212.10711">Task Ambiguity in Humans and Language Models</a></cite>
        <br>Alex Tamkin*, <b>Kunal Handa*</b>, Avash Shrestha, Noah Goodman. In the International Conference on Learning Representations (ICLR), 2023.</p>

        <h3 id="Journal Articles">Journal Articles</h3>
        <p><cite><a href="https://link.springer.com/article/10.3758/s13428-022-01906-4">Peekbank: An open, large-scale repository for developmental eye-tracking data of children's word recognition</a></cite>
        <br>Martin Zettersten... <b>Kunal Handa</b>... & Michael C Frank.<label for="authorship" class="margin-toggle sidenote-number"></label><input type="checkbox" id="authorship" class="margin-toggle"/><span class="sidenote">outside of the position of the first and the last author, authorship position was determined by sorting authors' last names in reverse alphabetical order.</span> In Behavior Research Methods (BRM), 2022.</p>
      </section>

      <section>
        <h2 id="Other Writing">Other Writing</h2>
        <p><cite><a href="https://cs.brown.edu/about/conduit/">The Role of Technology in Elections: The Voyage of Voters' Data</a></cite>
        <br><b>Kunal Handa.</b> In Conduit, the Brown University Computer Science Annual Magazine, Volume 32, 2022.</p>

        <p><cite><a href="https://docs.google.com/document/d/1ubSFQExPFSXXleB6fPT-4Tdg_9eS4trjVt9k-viAgHI/edit?usp=sharing">Trying to Give a Shit About <em>"Give a Shit"</em>: A Compositional Semantics Perspective</a></cite>
        <br><b>Kunal Handa</b><p>
        
      </section>

      <section>
        <h2 id="Teaching">Teaching</h2>
      <p>At Brown, I served as the Socially-Responsible Computing Teaching Assistant for CS1470: Deep Learning. I designed content<label for="STA content" class="margin-toggle sidenote-number"></label><input type="checkbox" id="STA content" class="margin-toggle"/><span class="sidenote">some of which is available via <a href="https://brown-deep-learning.github.io/dl-website-f22/assignments.html">the course's website</a></span> on deep learning's potential societal harms and conducted exercises that examined ethical frameworks, the cyclical nature of language models' biases, and the pros and cons of regulating ML advancements.</p> 

      <p>As a senior, I founded and led Brown's Explainable AI Reading Group. We presented and discussed topics across language modeling, reinforcement learning, computer vision, and multi-agent systems literature. </p>

      <p>I also tutor incarcerated and previously incarcerated individuals in HiSET test preparation and essay writing. Intermittently, I teach group classes such as Applying to College and Introduction to Philosophy at juvenile detention centers.</p>
      <section>
        <h2 id="Academic Service">Academic Service</h2>
        <p>I reviewed for Empirical Methods in Natural Language Processing (EMNLP), 2023; and, I reviewed for the Socially Responsible Language Modelling Research (SoLaR) Workshop at the Conference on Neural Information Processing Systems (NeurIPS), 2023.</p>
      </section>
    </article>
  </body>
</html>
