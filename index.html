<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>Kunal Handa</title>
    <link rel="stylesheet" href="tufte.css"/>
    <link rel="stylesheet" href="latex.css"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>

  <body>
    <article>
      <h1 id="Kunal Handa">Kunal Handa</h1>
      <section>
        <p><label for="mn-figure-1" class="margin-toggle">&#8853;</label><input type="checkbox" id="mn-figure-1" class="margin-toggle"/><span class="marginnote"> <img src="img/me.jpg" onmouseover="this.src='img/yodie.jpg'" onmouseout="this.src='img/me.jpg'" border="0" width="400" height=auto></span></p>

        <p><span class="newthought">I am a MSc by Research student</span>  at the University of Oxford advised by <a href="https://www.cs.ox.ac.uk/people/yarin.gal/website">Yarin Gal</a>. Previously, I was a linguistics and computer science undergrad at Brown University advised by <a href="https://cs.brown.edu/people/epavlick/">Ellie Pavlick</a> and <a href="https://chensun.me/index.html">Chen Sun</a>. I am broadly interested in understanding the fundamentals of learning in humans and machines: 1) applying the principles of human learning to ML—building ML models that can learn in the real world, where inputs are often vague or poorly specified and 2) using these models to supplement how humans learn.</p>
          
        <p>I {am, have been} fortunate to work with some amazing people as a part of the <a href="https://oatml.cs.ox.ac.uk/">Oxford OATML Group</a>, <a href="https://cocolab.stanford.edu/">Stanford CoCoLab</a>, <a href="https://lunar.cs.brown.edu/#">Brown LUNAR Lab</a>, <a href="https://nlp.stanford.edu/">Stanford NLP Group</a>, <a href="https://chensun.me/">Brown PALM Lab</a>, and <a href="https://langcog.stanford.edu/">Stanford LangCog Lab</a>.</p>
        
        <p>You can contact me at: kunal <var>[underscore]</var> handa <var>[at]</var> alumni <var>[dot]</var> brown <var>[dot]</var> edu</p>
      </section>

      <section>
        <h2 id="Currently">Currently,</h2>
        <p>I'm exploring how to improve large language models' preference-learning abilities with <a href="https://www.alextamkin.com/">Alex Tamkin</a>, <a href="https://belindal.github.io/">Belinda Li</a>, <a href="https://cs.brown.edu/people/epavlick/">Ellie Pavlick</a>, <a href="https://cocolab.stanford.edu/ndg">Noah Goodman</a>, and <a href="https://www.mit.edu/~jda/">Jacob Andreas</a>.</p>

        <p>
          I'm developing a novel formulation for uncertainty in LMs with <a href="https://www.cs.ox.ac.uk/people/yarin.gal/website/">Yarin Gal.</a>
        </p>
      </section>

      <section>
        <h2 id="Publications">Publications</h2>
        <h3 id="Conference Papers">Conference Papers</h3>
        <p><cite><a href="https://arxiv.org/abs/2310.10637">“Mistakes Help Us Grow”: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms</a></cite>
        <br><b>Kunal Handa</b>, Margarett Clapper, Jessica Boyle, Rose E Wang, Diyi Yang, David S Yeager, Dorottya Demszky. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023.</p>

        <p><cite><a href="https://arxiv.org/abs/2311.02171">Emergence of Abstract State Representations in Embodied Sequence Modeling</a></cite>
        <br>Tian Yun*, Zilai Zeng*, <b>Kunal Handa</b>, Ashish V Thapliyal, Bo Pang, Ellie Pavlick, Chen Sun. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023.</p>

        <p><cite><a href="https://arxiv.org/abs/2212.10711">Task Ambiguity in Humans and Language Models</a></cite>
        <br>Alex Tamkin*, <b>Kunal Handa*</b><label for="co-first" class="margin-toggle sidenote-number"></label><input type="checkbox" id="co-first" class="margin-toggle"/><span class="sidenote">* denotes equal contribution.</span>, Avash Shrestha, Noah Goodman. In the International Conference on Learning Representations (ICLR), 2023.</p>

        <h3 id="Journal Articles">Journal Articles</h3>
        <p><cite><a href="https://link.springer.com/article/10.3758/s13428-022-01906-4">Peekbank: An open, large-scale repository for developmental eye-tracking data of children's word recognition</a></cite>
        <br>Martin Zettersten... <b>Kunal Handa</b>... & Michael C Frank. In Behavior Research Methods (BRM), 2022.</p>
      </section>

      <section>
        <h2 id="Other Writing">Other Writing</h2>
        <p><cite><a href="https://cs.brown.edu/about/conduit/">The Role of Technology in Elections: The Voyage of Voters' Data</a></cite>
        <br><b>Kunal Handa.</b> In Conduit, the Brown University Computer Science Annual Magazine, Volume 32, 2022.</p>

        <p><cite><a href="https://docs.google.com/document/d/1ubSFQExPFSXXleB6fPT-4Tdg_9eS4trjVt9k-viAgHI/edit?usp=sharing">Trying to Give a Shit About <em>"Give a Shit"</em>: A Compositional Semantics Perspective</a></cite>
        <br><b>Kunal Handa</b><p>
        
      </section>

      <section>
        <h2 id="Teaching">Teaching</h2>
      <p>At Brown, I served as the Socially-Responsible Computing Teaching Assistant for CS1470: Deep Learning. I designed content<label for="STA content" class="margin-toggle sidenote-number"></label><input type="checkbox" id="STA content" class="margin-toggle"/><span class="sidenote">some of which is available via <a href="https://brown-deep-learning.github.io/dl-website-f22/assignments.html">the course's website</a></span> on deep learning's potential societal harms and conducted exercises that examined ethical frameworks, the cyclical nature of language models' biases, and the pros and cons of regulating ML advancements.</p>

      <p>I also tutor incarcerated and previously incarcerated individuals in HiSET test preparation and essay writing. Intermittently, I teach group classes such as Applying to College and Introduction to Philosophy at juvenile detention centers.</p>
      <section>
        <h2 id="Academic Service">Academic Service</h2>
        <p>I reviewed for Empirical Methods in Natural Language Processing (EMNLP), 2023; and, I reviewed for the Socially Responsible Language Modelling Research (SoLaR) Workshop at the Conference on Neural Information Processing Systems (NeurIPS), 2023.</p>
      </section>
    </article>
  </body>
</html>
